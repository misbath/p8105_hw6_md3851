---
title: "p8105_hw6_md3851"
author: "Misbath Daouda"
date: "11/19/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(broom)
library(modelr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

#Problem 1 

```{r}
bwt_data = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate( 
    babysex = as.factor(babysex),
    babysex = recode(babysex, "1" = "male", "2" = "female"),
    frace = as.factor(frace),
    frace = recode(frace, "1" = "white", "2" = "black", "3" = "asian", "4" = "puerto rican", "8" = "other", "9" = "unkown"),
    malform = as.factor(malform),
    malform = recode(malform, "0" = "absent", "1" = "present"),
    mrace = as.factor(mrace),
    mrace = recode(mrace, "1" = "white", "2" = "black", "3" = "asian", "4" = "puerto rican", "8" = "other")
    ) %>%
  drop_na() 

bwt_data
```

```{r}
model_selection = lm(bwt ~., data = bwt_data) %>% 
  MASS::stepAIC(direction = "both", trace = FALSE) %>% 
  summary()

model_selection
```

Model selection was automated with the stepAIC function from the MASS package. The direction was set to "both" so that both forward and backward selection were completed. The results return the best model, which is then labeled as model_1 below. 

```{r}

model_1 = lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = bwt_data)

bwt_data %>% 
  add_residuals(model_1) %>%
  add_predictions(model_1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(
       title = "Model_1 Residual Plot", 
       x = "Predictions",
       y = "Standardized Residuals")

model_2 = lm(bwt ~ blength + gaweeks, data = bwt_data)

bwt_data %>% 
  add_residuals(model_2) %>%
  add_predictions(model_2) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(
       title = "Model_2 Residual Plot", 
       x = "Predictions",
       y = "Standardized Residuals")

model_3 = lm(bwt ~ bhead + blength + babysex +  bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = bwt_data)

bwt_data %>% 
  add_residuals(model_3) %>%
  add_predictions(model_3) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(
       title = "Model_3 Residual Plot", 
       x = "Predictions",
       y = "Standardized Residuals")
```

The three models and their associated residual plots are presented above. 

```{r}
cv_df = 
  crossv_mc(bwt_data, 100)

cv_df = cv_df %>% 
  mutate(model_1  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
         model_2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_3  = map(train, ~lm(bwt ~ bhead + blength + babysex +  bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
         rmse_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
         rmse_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))

cv_plot = cv_df %>% 
  select(starts_with("rmse"))%>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

cv_plot 
```

The cross-validation plot above shows the distribution of RMSE values for each candidate model. The RMSE is the square root of the variance of the residuals. It indicates the absolute fit of the model to the data–how close the observed data points are to the model’s predicted values. Given that model_1 has the lowest RMSE values, this suggests that it performs better than the two other models. Similarly, model_2 performs better than model_3. 

#Problem 2

```{r, message = FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

boot_straps_tidy = weather_df %>% 
  bootstrap(n=5000) %>% 
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)),
         results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(-std.error, -statistic, -p.value) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  rename(beta1 = tmin, beta0 = `(Intercept)`) %>% 
  mutate(log = log(beta0*beta1))

boot_straps_tidy

boot_straps_glance = weather_df %>% 
  bootstrap(n=5000) %>% 
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
         results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(.id, r.squared)

boot_straps_glance
```

```{r plots}
log_plot = boot_straps_tidy %>% 
  ggplot(aes(x = log)) +
         geom_density()
log_plot

r_sq_plot = boot_straps_glance %>% 
  ggplot(aes(x = r.squared)) +
         geom_density()
r_sq_plot 

```

```{r CIs}
CI_rsquared = 
  boot_straps_glance %>% 
    summarize(
    perc_2.5 = round(quantile(r.squared, 0.025),2),
    perc_97.5 = round(quantile(r.squared, 0.975),2)) %>%
  knitr::kable()

CI_rsquared

CI_log = 
  boot_straps_tidy %>% 
    summarize(
    perc_2.5 = round(quantile(log, 0.025),2),
    perc_97.5 = round(quantile(log, 0.975),2)) %>%
  knitr::kable()

CI_log

#quantile(pull(boot_straps_tidy, log), probs =c(0.025, 0.975))

#quantile(pull(boot_straps_glance, r.squared), probs =c(0.025, 0.975))

```

  



